{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~etuptools (C:\\Users\\vkr82\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\vkr82\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ympy (C:\\Users\\vkr82\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~etuptools (C:\\Users\\vkr82\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\vkr82\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ympy (C:\\Users\\vkr82\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~etuptools (C:\\Users\\vkr82\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\vkr82\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ympy (C:\\Users\\vkr82\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-intel 2.16.2 requires ml-dtypes~=0.3.1, but you have ml-dtypes 0.5.3 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: opencv-python in c:\\users\\vkr82\\appdata\\roaming\\python\\python312\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: mediapipe in c:\\users\\vkr82\\appdata\\roaming\\python\\python312\\site-packages (0.10.21)\n",
      "Requirement already satisfied: torch in c:\\users\\vkr82\\appdata\\roaming\\python\\python312\\site-packages (2.8.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\vkr82\\appdata\\roaming\\python\\python312\\site-packages (0.23.0)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\vkr82\\appdata\\roaming\\python\\python312\\site-packages (2.8.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\vkr82\\appdata\\roaming\\python\\python312\\site-packages (4.67.0)\n",
      "Requirement already satisfied: pyttsx3 in c:\\users\\vkr82\\appdata\\roaming\\python\\python312\\site-packages (2.99)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\vkr82\\appdata\\roaming\\python\\python312\\site-packages (from opencv-python) (1.26.4)\n",
      "Requirement already satisfied: absl-py in c:\\users\\vkr82\\appdata\\roaming\\python\\python312\\site-packages (from mediapipe) (2.1.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\vkr82\\appdata\\roaming\\python\\python312\\site-packages (from mediapipe) (24.2.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\vkr82\\appdata\\roaming\\python\\python312\\site-packages (from mediapipe) (24.3.25)\n",
      "Collecting jax (from mediapipe)\n",
      "  Using cached jax-0.7.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting jaxlib (from mediapipe)\n",
      "  Using cached jaxlib-0.7.2-cp312-cp312-win_amd64.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\vkr82\\appdata\\roaming\\python\\python312\\site-packages (from mediapipe) (3.9.3)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\vkr82\\appdata\\roaming\\python\\python312\\site-packages (from mediapipe) (4.11.0.86)\n",
      "Requirement already satisfied: protobuf<5,>=4.25.3 in c:\\users\\vkr82\\appdata\\roaming\\python\\python312\\site-packages (from mediapipe) (4.25.8)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in c:\\users\\vkr82\\appdata\\roaming\\python\\python312\\site-packages (from mediapipe) (0.5.2)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\vkr82\\appdata\\roaming\\python\\python312\\site-packages (from mediapipe) (0.2.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\vkr82\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\vkr82\\appdata\\roaming\\python\\python312\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\vkr82\\appdata\\roaming\\python\\python312\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\vkr82\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\vkr82\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\vkr82\\appdata\\roaming\\python\\python312\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\vkr82\\appdata\\roaming\\python\\python312\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\vkr82\\appdata\\roaming\\python\\python312\\site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\vkr82\\appdata\\roaming\\python\\python312\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: comtypes in c:\\users\\vkr82\\appdata\\roaming\\python\\python312\\site-packages (from pyttsx3) (1.4.13)\n",
      "Requirement already satisfied: pypiwin32 in c:\\users\\vkr82\\appdata\\roaming\\python\\python312\\site-packages (from pyttsx3) (223)\n",
      "Requirement already satisfied: pywin32 in c:\\users\\vkr82\\appdata\\roaming\\python\\python312\\site-packages (from pyttsx3) (308)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\users\\vkr82\\appdata\\roaming\\python\\python312\\site-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\vkr82\\appdata\\roaming\\python\\python312\\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\vkr82\\appdata\\roaming\\python\\python312\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Collecting ml_dtypes>=0.5.0 (from jax->mediapipe)\n",
      "  Using cached ml_dtypes-0.5.3-cp312-cp312-win_amd64.whl.metadata (9.2 kB)\n",
      "INFO: pip is looking at multiple versions of jax to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting jax (from mediapipe)\n",
      "  Using cached jax-0.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting jaxlib (from mediapipe)\n",
      "  Using cached jaxlib-0.7.1-cp312-cp312-win_amd64.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: opt_einsum in c:\\users\\vkr82\\appdata\\roaming\\python\\python312\\site-packages (from jax->mediapipe) (3.3.0)\n",
      "Requirement already satisfied: scipy>=1.12 in c:\\users\\vkr82\\appdata\\roaming\\python\\python312\\site-packages (from jax->mediapipe) (1.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\vkr82\\appdata\\roaming\\python\\python312\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\vkr82\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->mediapipe) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\vkr82\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->mediapipe) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\vkr82\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->mediapipe) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\vkr82\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->mediapipe) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\vkr82\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->mediapipe) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\vkr82\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->mediapipe) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\vkr82\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\vkr82\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
      "Using cached jax-0.7.1-py3-none-any.whl (2.8 MB)\n",
      "Using cached jaxlib-0.7.1-cp312-cp312-win_amd64.whl (61.2 MB)\n",
      "Using cached ml_dtypes-0.5.3-cp312-cp312-win_amd64.whl (208 kB)\n",
      "Installing collected packages: ml_dtypes, jaxlib, jax\n",
      "\n",
      "  Attempting uninstall: ml_dtypes\n",
      "\n",
      "    Found existing installation: ml-dtypes 0.3.1\n",
      "\n",
      "    Uninstalling ml-dtypes-0.3.1:\n",
      "\n",
      "      Successfully uninstalled ml-dtypes-0.3.1\n",
      "\n",
      "   ---------------------------------------- 0/3 [ml_dtypes]\n",
      "   ---------------------------------------- 0/3 [ml_dtypes]\n",
      "   ------------- -------------------------- 1/3 [jaxlib]\n",
      "   ------------- -------------------------- 1/3 [jaxlib]\n",
      "   ------------- -------------------------- 1/3 [jaxlib]\n",
      "   ------------- -------------------------- 1/3 [jaxlib]\n",
      "   ------------- -------------------------- 1/3 [jaxlib]\n",
      "   ------------- -------------------------- 1/3 [jaxlib]\n",
      "   ------------- -------------------------- 1/3 [jaxlib]\n",
      "   ------------- -------------------------- 1/3 [jaxlib]\n",
      "   ------------- -------------------------- 1/3 [jaxlib]\n",
      "   ------------- -------------------------- 1/3 [jaxlib]\n",
      "   ------------- -------------------------- 1/3 [jaxlib]\n",
      "   ------------- -------------------------- 1/3 [jaxlib]\n",
      "   ------------- -------------------------- 1/3 [jaxlib]\n",
      "   ------------- -------------------------- 1/3 [jaxlib]\n",
      "   ------------- -------------------------- 1/3 [jaxlib]\n",
      "   ------------- -------------------------- 1/3 [jaxlib]\n",
      "   ------------- -------------------------- 1/3 [jaxlib]\n",
      "   ------------- -------------------------- 1/3 [jaxlib]\n",
      "   ------------- -------------------------- 1/3 [jaxlib]\n",
      "   ------------- -------------------------- 1/3 [jaxlib]\n",
      "   ------------- -------------------------- 1/3 [jaxlib]\n",
      "   ------------- -------------------------- 1/3 [jaxlib]\n",
      "   ------------- -------------------------- 1/3 [jaxlib]\n",
      "   ------------- -------------------------- 1/3 [jaxlib]\n",
      "   ------------- -------------------------- 1/3 [jaxlib]\n",
      "   ------------- -------------------------- 1/3 [jaxlib]\n",
      "   ------------- -------------------------- 1/3 [jaxlib]\n",
      "   ------------- -------------------------- 1/3 [jaxlib]\n",
      "   ------------- -------------------------- 1/3 [jaxlib]\n",
      "   ------------- -------------------------- 1/3 [jaxlib]\n",
      "   ------------- -------------------------- 1/3 [jaxlib]\n",
      "   ------------- -------------------------- 1/3 [jaxlib]\n",
      "   ------------- -------------------------- 1/3 [jaxlib]\n",
      "   ------------- -------------------------- 1/3 [jaxlib]\n",
      "   ------------- -------------------------- 1/3 [jaxlib]\n",
      "   ------------- -------------------------- 1/3 [jaxlib]\n",
      "   ------------- -------------------------- 1/3 [jaxlib]\n",
      "   ------------- -------------------------- 1/3 [jaxlib]\n",
      "   ------------- -------------------------- 1/3 [jaxlib]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   -------------------------- ------------- 2/3 [jax]\n",
      "   ---------------------------------------- 3/3 [jax]\n",
      "\n",
      "Successfully installed jax-0.7.1 jaxlib-0.7.1 ml_dtypes-0.5.3\n"
     ]
    }
   ],
   "source": [
    "# Run this in a Jupyter cell with a leading ! or in terminal\n",
    "!pip install opencv-python mediapipe torch torchvision torchaudio tqdm pyttsx3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Single Gesture Recorder\n",
    "# -----------------------------\n",
    "\n",
    "import cv2, os, time\n",
    "\n",
    "# ✅ Change this to the gesture you want to record\n",
    "gesture = \"Water\"  \n",
    "\n",
    "BASE_DIR = \"dataset\"\n",
    "os.makedirs(BASE_DIR, exist_ok=True)\n",
    "os.makedirs(os.path.join(BASE_DIR, gesture), exist_ok=True)\n",
    "\n",
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS) or 20.0\n",
    "\n",
    "# Count existing recordings\n",
    "count = len(os.listdir(os.path.join(BASE_DIR, gesture)))\n",
    "print(f\"Recording gesture: {gesture}\")\n",
    "print(\"Press 'r' to start recording a ~2s clip. Press 'q' to quit.\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    cv2.imshow(\"Single Gesture Recorder\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    \n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    \n",
    "    # Press 'r' to record\n",
    "    if key == ord('r'):\n",
    "        out_name = f\"{gesture}_{count}.mp4\"\n",
    "        out_path = os.path.join(BASE_DIR, gesture, out_name)\n",
    "        h, w = frame.shape[:2]\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        writer = cv2.VideoWriter(out_path, fourcc, 20.0, (w, h))\n",
    "        print(f\"Recording {gesture} -> {out_path}\")\n",
    "        start = time.time()\n",
    "        # Record ~2 seconds\n",
    "        while time.time() - start < 2.0:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret: break\n",
    "            writer.write(frame)\n",
    "            cv2.imshow(\"Single Gesture Recorder\", frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        writer.release()\n",
    "        count += 1\n",
    "        print(f\"Saved {out_path}\")\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mglob\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mcv2\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mmediapipe\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m mp_hands \u001b[38;5;241m=\u001b[39m mp\u001b[38;5;241m.\u001b[39msolutions\u001b[38;5;241m.\u001b[39mhands\n\u001b[0;32m      4\u001b[0m BASE\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\numpy\\__init__.py:144\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _distributor_init\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__config__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m show \u001b[38;5;28;01mas\u001b[39;00m show_config\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    146\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mError importing numpy: you should not try to import numpy from\u001b[39m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;124m    its source directory; please exit the numpy source tree, and relaunch\u001b[39m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;124m    your python interpreter from there.\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\numpy\\__config__.py:4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# This file is generated by numpy's build process\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# It contains system_info results at the time of building this package.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01menum\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Enum\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_multiarray_umath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      5\u001b[0m     __cpu_features__,\n\u001b[0;32m      6\u001b[0m     __cpu_baseline__,\n\u001b[0;32m      7\u001b[0m     __cpu_dispatch__,\n\u001b[0;32m      8\u001b[0m )\n\u001b[0;32m     10\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshow\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     11\u001b[0m _built_with_meson \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\numpy\\core\\__init__.py:24\u001b[0m\n\u001b[0;32m     21\u001b[0m         env_added\u001b[38;5;241m.\u001b[39mappend(envkey)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 24\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m multiarray\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\numpy\\core\\multiarray.py:10\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mCreate the numpy.core.multiarray namespace for backward compatibility. In v1.16\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mthe multiarray and umath c-extension modules were merged into a single\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      6\u001b[0m \n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m overrides\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _multiarray_umath\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_multiarray_umath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\numpy\\core\\overrides.py:8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m set_module\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_utils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_inspect\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m getargspec\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_multiarray_umath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      9\u001b[0m     add_docstring,  _get_implementing_args, _ArrayFunctionDispatcher)\n\u001b[0;32m     12\u001b[0m ARRAY_FUNCTIONS \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m     14\u001b[0m array_function_like_doc \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     15\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"like : array_like, optional\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03m        Reference object to allow the creation of arrays which are not\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;124;03m        compatible with that passed in via this argument.\"\"\"\u001b[39;00m\n\u001b[0;32m     21\u001b[0m )\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:463\u001b[0m, in \u001b[0;36m_lock_unlock_module\u001b[1;34m(name)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os, glob, numpy as np, cv2, mediapipe as mp\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "BASE=\"dataset\"\n",
    "OUT=\"processed/keypoints\"\n",
    "os.makedirs(OUT, exist_ok=True)\n",
    "SEQ_LEN = 20  # smaller seq_len for CPU\n",
    "\n",
    "def extract_keypoints_from_video(path, seq_len=SEQ_LEN):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    hands = mp_hands.Hands(static_image_mode=False, max_num_hands=2, min_detection_confidence=0.5)\n",
    "    seq=[]\n",
    "    while len(seq) < seq_len:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret: break\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        res = hands.process(rgb)\n",
    "        if res.multi_hand_landmarks:\n",
    "            data=[]\n",
    "            for hand in res.multi_hand_landmarks:\n",
    "                for lm in hand.landmark:\n",
    "                    data += [lm.x, lm.y, lm.z]\n",
    "            if len(res.multi_hand_landmarks)==1:\n",
    "                data += [0]*63\n",
    "            seq.append(data)\n",
    "        else:\n",
    "            seq.append([0]*126)\n",
    "    while len(seq) < seq_len:\n",
    "        seq.append([0]*126)\n",
    "    cap.release(); hands.close()\n",
    "    return np.array(seq, dtype=np.float32)\n",
    "\n",
    "for gesture in sorted(os.listdir(BASE)):\n",
    "    in_dir = os.path.join(BASE, gesture)\n",
    "    out_dir = os.path.join(OUT, gesture)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    for mp4 in glob.glob(os.path.join(in_dir,\"*.mp4\")):\n",
    "        name = os.path.splitext(os.path.basename(mp4))[0]\n",
    "        out_path = os.path.join(out_dir, name + \".npy\")\n",
    "        if os.path.exists(out_path): continue\n",
    "        arr = extract_keypoints_from_video(mp4)\n",
    "        np.save(out_path, arr)\n",
    "        print(\"Saved\", out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved frames processed/frames\\Food\\Food_5.npy\n",
      "Saved frames processed/frames\\Food\\Food_6.npy\n",
      "Saved frames processed/frames\\I\\I_5.npy\n",
      "Saved frames processed/frames\\I\\I_6.npy\n",
      "Saved frames processed/frames\\Sorry\\Sorry_5.npy\n",
      "Saved frames processed/frames\\Sorry\\Sorry_6.npy\n",
      "Saved frames processed/frames\\ThankYou\\ThankYou_5.npy\n",
      "Saved frames processed/frames\\ThankYou\\ThankYou_6.npy\n",
      "Saved frames processed/frames\\ThankYou\\ThankYou_7.npy\n",
      "Saved frames processed/frames\\Water\\Water_5.npy\n",
      "Saved frames processed/frames\\Water\\Water_6.npy\n",
      "Saved frames processed/frames\\Water\\Water_7.npy\n",
      "Saved frames processed/frames\\Water\\Water_8.npy\n"
     ]
    }
   ],
   "source": [
    "BASE=\"dataset\"\n",
    "OUT=\"processed/frames\"\n",
    "os.makedirs(OUT, exist_ok=True)\n",
    "TARGET_FRAMES = 8    # fewer frames\n",
    "TARGET_SIZE = (64,64)  # smaller resolution\n",
    "\n",
    "def extract_video_clip(path, target_frames=TARGET_FRAMES, size=TARGET_SIZE):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frames=[]\n",
    "    while len(frames) < target_frames:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret: break\n",
    "        frame = cv2.resize(frame, size)\n",
    "        frames.append(frame[..., ::-1])\n",
    "    cap.release()\n",
    "    while len(frames) < target_frames:\n",
    "        frames.append(frames[-1] if frames else np.zeros((size[1],size[0],3), dtype=np.uint8))\n",
    "    arr = np.stack(frames, axis=0).astype(np.uint8)\n",
    "    return arr\n",
    "\n",
    "for gesture in sorted(os.listdir(BASE)):\n",
    "    in_dir = os.path.join(BASE,gesture)\n",
    "    out_dir = os.path.join(OUT,gesture)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    for mp4 in glob.glob(os.path.join(in_dir,\"*.mp4\")):\n",
    "        name = os.path.splitext(os.path.basename(mp4))[0]\n",
    "        out_path = os.path.join(out_dir, name + \".npy\")\n",
    "        if os.path.exists(out_path): continue\n",
    "        clip = extract_video_clip(mp4)\n",
    "        np.save(out_path, clip)\n",
    "        print(\"Saved frames\", out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in c:\\users\\vkr82\\appdata\\roaming\\python\\python312\\site-packages (2.8.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\vkr82\\appdata\\roaming\\python\\python312\\site-packages (0.23.0)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\vkr82\\appdata\\roaming\\python\\python312\\site-packages (2.8.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\vkr82\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\vkr82\\appdata\\roaming\\python\\python312\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\vkr82\\appdata\\roaming\\python\\python312\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\vkr82\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\vkr82\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\vkr82\\appdata\\roaming\\python\\python312\\site-packages (from torch) (2024.6.1)\n",
      "Collecting setuptools (from torch)\n",
      "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\vkr82\\appdata\\roaming\\python\\python312\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\vkr82\\appdata\\roaming\\python\\python312\\site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\vkr82\\appdata\\roaming\\python\\python312\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\vkr82\\appdata\\roaming\\python\\python312\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Using cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "Installing collected packages: setuptools\n",
      "Successfully installed setuptools-80.9.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~etuptools (C:\\Users\\vkr82\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\vkr82\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ympy (C:\\Users\\vkr82\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~etuptools (C:\\Users\\vkr82\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\vkr82\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ympy (C:\\Users\\vkr82\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~etuptools (C:\\Users\\vkr82\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\vkr82\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ympy (C:\\Users\\vkr82\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~etuptools (C:\\Users\\vkr82\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\vkr82\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ympy (C:\\Users\\vkr82\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-intel 2.16.2 requires ml-dtypes~=0.3.1, but you have ml-dtypes 0.5.3 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np, os, glob\n",
    "\n",
    "device = torch.device(\"cpu\")  # CPU only\n",
    "\n",
    "# Keypoint dataset\n",
    "class KeypointDataset(Dataset):\n",
    "    def __init__(self, root=\"processed/keypoints\"):\n",
    "        self.samples=[]; self.labels=[]\n",
    "        self.classes = sorted(os.listdir(root))\n",
    "        for i,cls in enumerate(self.classes):\n",
    "            for npy in glob.glob(os.path.join(root,cls,\"*.npy\")):\n",
    "                self.samples.append(npy)\n",
    "                self.labels.append(i)\n",
    "    def __len__(self): return len(self.samples)\n",
    "    def __getitem__(self, idx):\n",
    "        arr = np.load(self.samples[idx])\n",
    "        return torch.tensor(arr, dtype=torch.float32), self.labels[idx]\n",
    "\n",
    "# Frame dataset\n",
    "import os, glob\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import cv2\n",
    "\n",
    "class VideoDataset(Dataset):\n",
    "    def __init__(self, root=\"processed/frames\", seq_len=12, resize=(32,32)):\n",
    "        self.samples = []\n",
    "        self.labels = []\n",
    "        self.seq_len = seq_len\n",
    "        self.resize = resize\n",
    "        self.classes = sorted(os.listdir(root))\n",
    "        self.class2idx = {c:i for i,c in enumerate(self.classes)}\n",
    "\n",
    "        for cls in self.classes:\n",
    "            cls_path = os.path.join(root, cls)\n",
    "            for npy in glob.glob(os.path.join(cls_path, \"*.npy\")):\n",
    "                self.samples.append(npy)\n",
    "                self.labels.append(self.class2idx[cls])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        arr = np.load(self.samples[idx]).astype(np.float32)/255.0  # normalize\n",
    "        # Pad or crop sequence to seq_len\n",
    "        T, H, W, C = arr.shape\n",
    "        if T < self.seq_len:\n",
    "            pad = np.zeros((self.seq_len - T, H, W, C), dtype=np.float32)\n",
    "            arr = np.concatenate([arr, pad], axis=0)\n",
    "        elif T > self.seq_len:\n",
    "            arr = arr[:self.seq_len]\n",
    "\n",
    "        # Resize frames if needed\n",
    "        if self.resize:\n",
    "            arr_resized = np.stack([cv2.resize(f, self.resize) for f in arr], axis=0)\n",
    "            arr = arr_resized\n",
    "\n",
    "        # Transpose to [C, T, H, W] for Conv3D\n",
    "        arr = np.transpose(arr, (3,0,1,2))\n",
    "        return torch.tensor(arr, dtype=torch.float32), self.labels[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class GestureLSTM(nn.Module):\n",
    "    def __init__(self, input_dim=126, hidden_dim=64, num_classes=5):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_dim*2, num_classes)\n",
    "    def forward(self,x):\n",
    "        out,_ = self.lstm(x)\n",
    "        return self.fc(out[:,-1,:])\n",
    "\n",
    "class Simple3DCNN(nn.Module):\n",
    "    def __init__(self, num_classes=5):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv3d(3,16,3,padding=1), nn.ReLU(), nn.MaxPool3d((1,2,2)),\n",
    "            nn.Conv3d(16,32,3,padding=1), nn.ReLU(), nn.MaxPool3d((2,2,2)),\n",
    "            nn.Conv3d(32,64,3,padding=1), nn.ReLU(), nn.AdaptiveAvgPool3d((1,1,1)),\n",
    "        )\n",
    "        self.fc = nn.Linear(64,num_classes)\n",
    "    def forward(self,x):\n",
    "        x=self.net(x)\n",
    "        x=x.view(x.size(0),-1)\n",
    "        return self.fc(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'processed/keypoints/I/I_0.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-198b5d290bd2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"processed/keypoints/I/I_0.npy\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m# Check the shape of the array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m         \u001b[1;31m# See the actual data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[0;32m    403\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 405\u001b[1;33m             \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    406\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'processed/keypoints/I/I_0.npy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Replace with your file path\n",
    "file_path = \"processed/keypoints/I/I_0.npy\"\n",
    "\n",
    "data = np.load(file_path)\n",
    "print(data.shape)   # Check the shape of the array\n",
    "print(data)         # See the actual data\n",
    "print(\"Sequence length:\", data.shape[0])\n",
    "print(\"Number of features per frame:\", data.shape[1])\n",
    "print(\"First frame keypoints:\", data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vkr82\\AppData\\Local\\Temp\\ipykernel_11536\\3108086273.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X=X.to(device); y=torch.tensor(y).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss=1.5629\n",
      "Epoch 2, loss=1.4068\n",
      "Epoch 3, loss=1.2419\n",
      "Epoch 4, loss=1.1303\n",
      "Epoch 5, loss=1.0127\n",
      "Epoch 6, loss=0.9781\n",
      "Epoch 7, loss=0.9404\n",
      "Epoch 8, loss=0.9342\n",
      "Epoch 9, loss=0.9497\n",
      "Epoch 10, loss=0.7466\n",
      "Epoch 11, loss=0.6346\n",
      "Epoch 12, loss=0.6057\n",
      "Epoch 13, loss=0.5275\n",
      "Epoch 14, loss=0.7532\n",
      "Epoch 15, loss=0.8245\n",
      "Epoch 16, loss=0.6888\n",
      "Epoch 17, loss=0.6175\n",
      "Epoch 18, loss=0.5039\n",
      "Epoch 19, loss=0.4489\n",
      "Epoch 20, loss=0.4216\n",
      "Epoch 21, loss=0.3559\n",
      "Epoch 22, loss=0.7045\n",
      "Epoch 23, loss=0.7402\n",
      "Epoch 24, loss=1.0237\n",
      "Epoch 25, loss=0.6184\n",
      "Epoch 26, loss=0.5475\n",
      "Epoch 27, loss=0.5162\n",
      "Epoch 28, loss=0.4587\n",
      "Epoch 29, loss=0.4729\n",
      "Epoch 30, loss=0.3247\n",
      "Epoch 31, loss=0.3311\n",
      "Epoch 32, loss=0.3050\n",
      "Epoch 33, loss=0.2922\n",
      "Epoch 34, loss=0.3075\n",
      "Epoch 35, loss=0.2681\n",
      "Epoch 36, loss=0.2692\n",
      "Epoch 37, loss=0.2547\n",
      "Epoch 38, loss=0.3903\n",
      "Epoch 39, loss=0.7397\n",
      "Epoch 40, loss=0.4577\n",
      "Epoch 41, loss=0.3783\n",
      "Epoch 42, loss=0.3367\n",
      "Epoch 43, loss=0.2939\n",
      "Epoch 44, loss=0.2789\n",
      "Epoch 45, loss=0.2507\n",
      "Epoch 46, loss=0.2466\n",
      "Epoch 47, loss=0.3153\n",
      "Epoch 48, loss=0.1760\n",
      "Epoch 49, loss=0.2768\n",
      "Epoch 50, loss=0.1517\n"
     ]
    }
   ],
   "source": [
    "kp_dataset = KeypointDataset(\"processed/keypoints\")\n",
    "kp_loader = DataLoader(kp_dataset, batch_size=4, shuffle=True)  # small batch\n",
    "\n",
    "model_kp = GestureLSTM(input_dim=kp_dataset[0][0].shape[1], hidden_dim=64, num_classes=len(kp_dataset.classes)).to(device)\n",
    "opt = torch.optim.Adam(model_kp.parameters(), lr=1e-3)\n",
    "crit = nn.CrossEntropyLoss()\n",
    "\n",
    "for ep in range(50):  # fewer epochs for CPU\n",
    "    total_loss=0; cnt=0\n",
    "    model_kp.train()\n",
    "    for X,y in kp_loader:\n",
    "        X=X.to(device); y=torch.tensor(y).to(device)\n",
    "        opt.zero_grad()\n",
    "        out = model_kp(X)\n",
    "        loss = crit(out,y)\n",
    "        loss.backward(); opt.step()\n",
    "        total_loss+=loss.item(); cnt+=1\n",
    "    print(f\"Epoch {ep+1}, loss={total_loss/cnt:.4f}\")\n",
    "torch.save(model_kp.state_dict(),\"gesture_lstm_cpu.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vkr82\\AppData\\Local\\Temp\\ipykernel_15832\\3355506031.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(y, dtype=torch.long).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3D Epoch 1/50, loss=1.6194\n",
      "3D Epoch 2/50, loss=1.6121\n",
      "3D Epoch 3/50, loss=1.6146\n",
      "3D Epoch 4/50, loss=1.6133\n",
      "3D Epoch 5/50, loss=1.6121\n",
      "3D Epoch 6/50, loss=1.6101\n",
      "3D Epoch 7/50, loss=1.6092\n",
      "3D Epoch 8/50, loss=1.6112\n",
      "3D Epoch 9/50, loss=1.6082\n",
      "3D Epoch 10/50, loss=1.6150\n",
      "3D Epoch 11/50, loss=1.6067\n",
      "3D Epoch 12/50, loss=1.6083\n",
      "3D Epoch 13/50, loss=1.6039\n",
      "3D Epoch 14/50, loss=1.6044\n",
      "3D Epoch 15/50, loss=1.6093\n",
      "3D Epoch 16/50, loss=1.6085\n",
      "3D Epoch 17/50, loss=1.6048\n",
      "3D Epoch 18/50, loss=1.6050\n",
      "3D Epoch 19/50, loss=1.5968\n",
      "3D Epoch 20/50, loss=1.5985\n",
      "3D Epoch 21/50, loss=1.6062\n",
      "3D Epoch 22/50, loss=1.6046\n",
      "3D Epoch 23/50, loss=1.5985\n",
      "3D Epoch 24/50, loss=1.5929\n",
      "3D Epoch 25/50, loss=1.6053\n",
      "3D Epoch 26/50, loss=1.6026\n",
      "3D Epoch 27/50, loss=1.6062\n",
      "3D Epoch 28/50, loss=1.6012\n",
      "3D Epoch 29/50, loss=1.5987\n",
      "3D Epoch 30/50, loss=1.5960\n",
      "3D Epoch 31/50, loss=1.5993\n",
      "3D Epoch 32/50, loss=1.5928\n",
      "3D Epoch 33/50, loss=1.6019\n",
      "3D Epoch 34/50, loss=1.6003\n",
      "3D Epoch 35/50, loss=1.5978\n",
      "3D Epoch 36/50, loss=1.5966\n",
      "3D Epoch 37/50, loss=1.5932\n",
      "3D Epoch 38/50, loss=1.5851\n",
      "3D Epoch 39/50, loss=1.5953\n",
      "3D Epoch 40/50, loss=1.5925\n",
      "3D Epoch 41/50, loss=1.5824\n",
      "3D Epoch 42/50, loss=1.5908\n",
      "3D Epoch 43/50, loss=1.5800\n",
      "3D Epoch 44/50, loss=1.5851\n",
      "3D Epoch 45/50, loss=1.5835\n",
      "3D Epoch 46/50, loss=1.5780\n",
      "3D Epoch 47/50, loss=1.5657\n",
      "3D Epoch 48/50, loss=1.5790\n",
      "3D Epoch 49/50, loss=1.5843\n",
      "3D Epoch 50/50, loss=1.5743\n",
      "Saved improved 3D-CNN model to gesture_3d_cpu.pth!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# --- Dataset ---\n",
    "# Make sure your VideoDataset class accepts seq_len and resize\n",
    "video_ds = VideoDataset(\"processed/frames\", seq_len=12, resize=(32,32))\n",
    "video_loader = DataLoader(video_ds, batch_size=4, shuffle=True)\n",
    "\n",
    "# --- Model ---\n",
    "model_3d = Simple3DCNN(num_classes=len(video_ds.classes)).to(device)\n",
    "opt3 = torch.optim.Adam(model_3d.parameters(), lr=1e-4)\n",
    "crit3 = nn.CrossEntropyLoss()\n",
    "\n",
    "# --- Training parameters ---\n",
    "num_epochs = 50  # can increase further for better accuracy\n",
    "\n",
    "for ep in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    cnt = 0\n",
    "    model_3d.train()\n",
    "    \n",
    "    for X, y in video_loader:\n",
    "        # Ensure correct tensor type\n",
    "        X = X.float().to(device)       # [batch, C, seq_len, H, W]\n",
    "        y = torch.tensor(y, dtype=torch.long).to(device)\n",
    "        \n",
    "        opt3.zero_grad()\n",
    "        out = model_3d(X)\n",
    "        loss = crit3(out, y)\n",
    "        loss.backward()\n",
    "        opt3.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        cnt += 1\n",
    "    \n",
    "    print(f\"3D Epoch {ep+1}/{num_epochs}, loss={total_loss/cnt:.4f}\")\n",
    "\n",
    "# --- Save model ---\n",
    "MODEL_SAVE_PATH = \"gesture_3d_cpu.pth\"\n",
    "torch.save(model_3d.state_dict(), MODEL_SAVE_PATH)\n",
    "print(f\"Saved improved 3D-CNN model to {MODEL_SAVE_PATH}!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'kp_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m         trues \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m accuracy_score(trues,preds)\n\u001b[1;32m---> 14\u001b[0m acc_kp \u001b[38;5;241m=\u001b[39m eval_model(model_kp,\u001b[43mkp_dataset\u001b[49m)\n\u001b[0;32m     15\u001b[0m acc_3d \u001b[38;5;241m=\u001b[39m eval_model(model_3d,video_ds)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLSTM CPU acc:\u001b[39m\u001b[38;5;124m\"\u001b[39m,acc_kp)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'kp_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "\n",
    "def eval_model(model, dataset, batch_size=1):\n",
    "    model.eval()\n",
    "    preds=[]; trues=[]\n",
    "    for X,y in DataLoader(dataset,batch_size=batch_size):\n",
    "        X=X.to(device)\n",
    "        with torch.no_grad(): out = model(X)\n",
    "        preds += out.argmax(1).cpu().numpy().tolist()\n",
    "        trues += y\n",
    "    return accuracy_score(trues,preds)\n",
    "\n",
    "acc_kp = eval_model(model_kp,kp_dataset)\n",
    "acc_3d = eval_model(model_3d,video_ds)\n",
    "print(\"LSTM CPU acc:\",acc_kp)\n",
    "print(\"3D-CNN CPU acc:\",acc_3d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GestureLSTM' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-7a25e8023c54>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;31m# Load model once\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m \u001b[0mmodel_kp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_lstm_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[0mspeaker\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwin32com\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"SAPI.SpVoice\"\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# <-- Windows TTS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-7a25e8023c54>\u001b[0m in \u001b[0;36mload_lstm_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# Function to load model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mload_lstm_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGestureLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m126\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGESTURES\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMODEL_PATH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMODEL_PATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'GestureLSTM' is not defined"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import cv2, mediapipe as mp\n",
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import win32com.client  # <-- Use win32com for TTS\n",
    "\n",
    "# -----------------------\n",
    "# Real-time LSTM Gesture Recognition (CPU)\n",
    "# -----------------------\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "SEQ_LEN = 20  # should match training\n",
    "GESTURES = [\"Food\", \"I\", \"Sorry\", \"Thank You\", \"Water\"]  # same as training\n",
    "device = torch.device(\"cpu\")\n",
    "MODEL_PATH = \"gesture_lstm_cpu.pth\"\n",
    "\n",
    "# Function to load model\n",
    "def load_lstm_model():\n",
    "    model = GestureLSTM(input_dim=126, hidden_dim=64, num_classes=len(GESTURES)).to(device)\n",
    "    if os.path.exists(MODEL_PATH):\n",
    "        model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "        model.eval()\n",
    "        print(\"Loaded trained model from\", MODEL_PATH)\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"{MODEL_PATH} not found. Train model first.\")\n",
    "    return model\n",
    "\n",
    "# Load model once\n",
    "model_kp = load_lstm_model()\n",
    "\n",
    "speaker = win32com.client.Dispatch(\"SAPI.SpVoice\")  # <-- Windows TTS\n",
    "last_spoken = None  # Track last spoken gesture\n",
    "COOLDOWN = 2  # seconds\n",
    "last_spoken_time = 0\n",
    "\n",
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "hands = mp_hands.Hands(\n",
    "    max_num_hands=2,\n",
    "    min_detection_confidence=0.3,  # lower threshold\n",
    "    min_tracking_confidence=0.3\n",
    ")\n",
    "buf = collections.deque(maxlen=SEQ_LEN)\n",
    "\n",
    "prev_time = 0  # for FPS calculation\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    res = hands.process(rgb)\n",
    "    \n",
    "    # Extract keypoints for LSTM\n",
    "    data = []\n",
    "    hands_detected = 0\n",
    "    if res.multi_hand_landmarks:\n",
    "        hands_detected = len(res.multi_hand_landmarks)\n",
    "        for i, hand in enumerate(res.multi_hand_landmarks):\n",
    "            if i >= 2:\n",
    "                break\n",
    "            for lm in hand.landmark:\n",
    "                data += [lm.x, lm.y, lm.z]\n",
    "        while len(data) < 126:\n",
    "            data += [0]\n",
    "        for hand_landmarks in res.multi_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "    else:\n",
    "        data = [0]*126\n",
    "\n",
    "    buf.append(np.array(data, dtype=np.float32))\n",
    "\n",
    "    # Show buffer status\n",
    "    cv2.putText(frame, f\"Buffer: {len(buf)}/{SEQ_LEN}\", (10, 110),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "\n",
    "    # Show warning if no hands\n",
    "    if hands_detected == 0:\n",
    "        cv2.putText(frame, \"No hands detected!\", (10, 140),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "\n",
    "    # Predict gesture only if at least one hand is detected\n",
    "    if len(buf) == SEQ_LEN and hands_detected > 0:\n",
    "        seq_input = torch.tensor([list(buf)], dtype=torch.float32).to(device)\n",
    "        with torch.no_grad():\n",
    "            out = model_kp(seq_input)\n",
    "            pred = out.argmax(dim=1).item()\n",
    "        gesture_word = GESTURES[pred]    \n",
    "        cv2.putText(frame, f\"Gesture: {gesture_word}\", (10, 40),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        print(f\"[DEBUG] Hands detected: {hands_detected}, Predicted gesture: {gesture_word}\")\n",
    "        \n",
    "        # Speak only if cooldown passed and gesture changed\n",
    "        if gesture_word != last_spoken and time.time() - last_spoken_time > COOLDOWN:\n",
    "            print(\"speaking:\", gesture_word)\n",
    "            speaker.Speak(gesture_word)  # <-- Use win32com for speech\n",
    "            print(\"done speaking\")\n",
    "            last_spoken = gesture_word\n",
    "            last_spoken_time = time.time()\n",
    "\n",
    "    # Calculate and display FPS\n",
    "    curr_time = time.time()\n",
    "    fps = 1 / (curr_time - prev_time) if prev_time else 0\n",
    "    prev_time = curr_time\n",
    "    cv2.putText(frame, f\"FPS: {int(fps)}\", (10, 80),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"Real-time Gesture Recognition\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.cache', '.conda', '.condarc', '.config', '.EasyOCR', '.gitconfig', '.idlerc', '.ipython', '.jupyter', '.keras', '.labelImgSettings.pkl', '.lesshst', '.matplotlib', '.MCTranscodingSDK', '.node_repl_history', '.openshot_qt', '.spyder-py3', '.vscode', '.wdm', '3D Objects', 'anaconda3', 'AppData', 'Application Data', 'c course', 'C++ course', 'computer science hhw', 'computer science practical file till lists.pdf', 'computer science practical file till tuples.pdf', 'computer science practical file.docx', 'computer science practical file.pdf', 'conditional and looping constructs for theory class.pdf', 'Contacts', 'Cookies', 'data.txt', 'data_science_course', 'Desktop', 'Documents', 'Downloads', 'englsh project asl.mp4', 'englsh project asl.osp', 'englsh project asl_assets', 'Favorites', 'gen ai', 'GST-CHALLAN.pdf', 'Homework11', 'IntelGraphicsProfiles', 'Links', 'Local Settings', 'maths sylabus.docx', 'Music', 'My Documents', 'NetHood', 'NTUSER.DAT', 'ntuser.dat.LOG1', 'ntuser.dat.LOG2', 'NTUSER.DAT{a2332f17-cdbf-11ec-8680-002248483d79}.TxR.0.regtrans-ms', 'NTUSER.DAT{a2332f17-cdbf-11ec-8680-002248483d79}.TxR.1.regtrans-ms', 'NTUSER.DAT{a2332f17-cdbf-11ec-8680-002248483d79}.TxR.2.regtrans-ms', 'NTUSER.DAT{a2332f17-cdbf-11ec-8680-002248483d79}.TxR.blf', 'NTUSER.DAT{a2332f18-cdbf-11ec-8680-002248483d79}.TM.blf', 'NTUSER.DAT{a2332f18-cdbf-11ec-8680-002248483d79}.TMContainer00000000000000000001.regtrans-ms', 'NTUSER.DAT{a2332f18-cdbf-11ec-8680-002248483d79}.TMContainer00000000000000000002.regtrans-ms', 'ntuser.ini', 'OneDrive', 'Pictures', 'practice python', 'PrintHood', 'python docs', 'qpython', 'Recent', 'Saved Games', 'Searches', 'SEM 1', 'SendTo', 'Start Menu', 'Submission DECEMBER CS', 'Templates', 'truthtable_diagram_only.pdf', 'tuples.pdf', 'UT2.docx', 'Videos', 'web development', 'XI-Conditional & Looping Constructs.pdf']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3D-CNN model successfully!\n",
      "speaking: Water\n",
      "done speaking\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 36\u001b[0m\n\u001b[0;32m     33\u001b[0m frames_tensor \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255.0\u001b[39m  \u001b[38;5;66;03m# normalize if model trained on [0,1]\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 36\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_3d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframes_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m     pred \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     38\u001b[0m gesture_word \u001b[38;5;241m=\u001b[39m GESTURES[pred]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[1], line 22\u001b[0m, in \u001b[0;36mSimple3DCNN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,x):\n\u001b[1;32m---> 22\u001b[0m     x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m     x\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mview(x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m),\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(x)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\container.py:244\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 244\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\conv.py:717\u001b[0m, in \u001b[0;36mConv3d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    716\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 717\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\conv.py:712\u001b[0m, in \u001b[0;36mConv3d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    700\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    701\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv3d(\n\u001b[0;32m    702\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[0;32m    703\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    710\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[0;32m    711\u001b[0m     )\n\u001b[1;32m--> 712\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv3d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    713\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[0;32m    714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "import win32com.client\n",
    "model_3d = Simple3DCNN(num_classes=len(GESTURES)).to(device)\n",
    "model_3d.load_state_dict(torch.load(\"gesture_3d_cpu.pth\", map_location=device))\n",
    "model_3d.eval()\n",
    "print(\"Loaded 3D-CNN model successfully!\")\n",
    "\n",
    "SEQ_LEN = 16  # match what was used in training\n",
    "frame_buffer = deque(maxlen=SEQ_LEN)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "speaker = win32com.client.Dispatch(\"SAPI.SpVoice\") \n",
    "\n",
    "last_spoken=None\n",
    "COOLDOWN = 2\n",
    "last_spoken_time = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Resize to 64x64 (or your training size)\n",
    "    frame_resized = cv2.resize(frame, (64,64))\n",
    "    frame_buffer.append(frame_resized)\n",
    "\n",
    "    # Predict when buffer is full\n",
    "    if len(frame_buffer) == SEQ_LEN:\n",
    "        # Convert buffer to tensor: [batch=1, C=3, seq, H, W]\n",
    "        frames_np = np.stack(frame_buffer, axis=0)       # [seq, H, W, C]\n",
    "        frames_np = frames_np.transpose(3,0,1,2)        # [C, seq, H, W]\n",
    "        frames_tensor = torch.tensor(frames_np, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "        frames_tensor /= 255.0  # normalize if model trained on [0,1]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = model_3d(frames_tensor)\n",
    "            pred = out.argmax(dim=1).item()\n",
    "        gesture_word = GESTURES[pred]\n",
    "        cv2.putText(frame, f\"3D-CNN Gesture: {gesture_word}\", (10,40),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),2)\n",
    "        # Speak only if cooldown passed and gesture changed\n",
    "        if gesture_word != last_spoken and time.time() - last_spoken_time > COOLDOWN:\n",
    "            print(\"speaking:\", gesture_word)\n",
    "            speaker.Speak(gesture_word)\n",
    "            print(\"done speaking\")\n",
    "            last_spoken = gesture_word\n",
    "            last_spoken_time = time.time()\n",
    "\n",
    "    cv2.imshow(\"3D-CNN Gesture Recognition\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
